{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16a513c-b4af-4151-b95a-34ebbf0e887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from gen_disc_networks import Generator, Discriminator\n",
    "from customDataSet import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263662f0-b6ca-4137-96ca-63618b782141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Hyperparameters\n",
    "\n",
    "pixel_size = 256\n",
    "batch_size = 4\n",
    "noise_dim = 2\n",
    "lr = 0.0002\n",
    "num_epochs = 50\n",
    "ifTrain = True\n",
    "ifSaveModel = True\n",
    "if ifTrain == True:\n",
    "    print(\"true\")\n",
    "else:\n",
    "    print(\"false\")\n",
    "\n",
    "G = Generator(noise_dim)\n",
    "D = Discriminator()\n",
    "#G.get_submodule\n",
    "\n",
    "generator = G.to(device)\n",
    "discriminator = D.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199d53b-ec70-46ac-88d9-2af5c27829b0",
   "metadata": {},
   "source": [
    "Getting the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1acdfc7-6338-43d5-a31b-86946c205364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator summary\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           3,072\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "            Conv2d-4          [-1, 128, 64, 64]         131,072\n",
      "       BatchNorm2d-5          [-1, 128, 64, 64]             256\n",
      "              ReLU-6          [-1, 128, 64, 64]               0\n",
      "            Conv2d-7          [-1, 256, 32, 32]         524,288\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "              ReLU-9          [-1, 256, 32, 32]               0\n",
      "           Conv2d-10          [-1, 512, 16, 16]       2,097,152\n",
      "      BatchNorm2d-11          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-12          [-1, 512, 16, 16]               0\n",
      "           Conv2d-13           [-1, 1024, 8, 8]       8,388,608\n",
      "      BatchNorm2d-14           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-15           [-1, 1024, 8, 8]               0\n",
      "  ConvTranspose2d-16          [-1, 512, 16, 16]       8,388,608\n",
      "      BatchNorm2d-17          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-18          [-1, 512, 16, 16]               0\n",
      "  ConvTranspose2d-19          [-1, 256, 32, 32]       2,097,152\n",
      "      BatchNorm2d-20          [-1, 256, 32, 32]             512\n",
      "             ReLU-21          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-22          [-1, 128, 64, 64]         524,288\n",
      "      BatchNorm2d-23          [-1, 128, 64, 64]             256\n",
      "             ReLU-24          [-1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-25         [-1, 64, 128, 128]         131,072\n",
      "      BatchNorm2d-26         [-1, 64, 128, 128]             128\n",
      "             ReLU-27         [-1, 64, 128, 128]               0\n",
      "  ConvTranspose2d-28          [-1, 1, 256, 256]           1,024\n",
      "             Tanh-29          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 22,292,224\n",
      "Trainable params: 22,292,224\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 32768.00\n",
      "Forward/backward pass size (MB): 92.50\n",
      "Params size (MB): 85.04\n",
      "Estimated Total Size (MB): 32945.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Generator summary\")\n",
    "summary(G, [(1, pixel_size, pixel_size), (noise_dim, pixel_size, pixel_size)])\n",
    "\n",
    "#print(\"Discriminator summary\")\n",
    "#summary(D, (2, 256, 256))\n",
    "#for parameter in G.parameters():\n",
    "#    print(parameter)\n",
    "# Initialize models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0db091-c210-4dfb-9b42-e28e88940554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instance\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((pixel_size, pixel_size)),  # Resize to pixel_size x pixel_size\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "])\n",
    "dataset_dpm_path = 'dataset/DPM/'\n",
    "dataset_irt_path = 'dataset/IRT2/'\n",
    "\n",
    "dataset = CustomDataset(dataset_dpm_path, dataset_irt_path, transform=transform)\n",
    "\n",
    "# Create data loader\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Choose a random index\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "# Get the image at the random index\n",
    "\n",
    "image_dpm, image_irt = dataset[random_index]\n",
    "\n",
    "# Convert tensor to numpy array and remove batch dimension\n",
    "image_dpm_np = image_dpm.squeeze().numpy()\n",
    "image_irt_np = image_irt.squeeze().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ff244-1268-4b1a-8744-e4e8734feafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n",
      "Epoch [0/50], Step [0/20], D_loss: 1.5260, G_loss: 2.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▎                         | 1/20 [00:03<01:02,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch {i}\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██▋                        | 2/20 [00:06<00:59,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████                       | 3/20 [00:10<00:58,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████▍                     | 4/20 [00:13<00:55,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████▊                    | 5/20 [00:17<00:51,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████                   | 6/20 [00:20<00:47,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████▍                 | 7/20 [00:23<00:43,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████▊                | 8/20 [00:27<00:40,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████▏              | 9/20 [00:30<00:36,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████             | 10/20 [00:33<00:33,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n",
      "Epoch [0/50], Step [10/20], D_loss: 0.0549, G_loss: 7.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████▎           | 11/20 [00:37<00:30,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch {i}\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████▌          | 12/20 [00:40<00:26,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████▉         | 13/20 [00:43<00:22,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████▏       | 14/20 [00:47<00:19,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████▌      | 15/20 [00:50<00:16,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████▊     | 16/20 [00:53<00:13,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████    | 17/20 [00:56<00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████▍  | 18/20 [01:00<00:06,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████▋ | 19/20 [01:03<00:03,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 20/20 [01:06<00:00,  3.34s/it]\n",
      "  0%|                                   | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n",
      "Epoch [1/50], Step [0/20], D_loss: 0.0080, G_loss: 7.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▎                         | 1/20 [00:03<01:11,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch {i}\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██▋                        | 2/20 [00:07<01:02,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████                       | 3/20 [00:10<00:57,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████▍                     | 4/20 [00:13<00:53,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████▊                    | 5/20 [00:16<00:49,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████                   | 6/20 [00:20<00:45,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████▍                 | 7/20 [00:23<00:42,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████▊                | 8/20 [00:26<00:39,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████▏              | 9/20 [00:29<00:35,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████             | 10/20 [00:33<00:32,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n",
      "Epoch [1/50], Step [10/20], D_loss: 0.0172, G_loss: 7.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████▎           | 11/20 [00:36<00:30,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch {i}\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████▌          | 12/20 [00:39<00:25,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████▉         | 13/20 [00:42<00:22,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████▏       | 14/20 [00:46<00:19,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████▌      | 15/20 [00:49<00:16,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████▊     | 16/20 [00:52<00:13,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████    | 17/20 [00:55<00:09,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████▍  | 18/20 [00:59<00:06,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████▋ | 19/20 [01:03<00:03,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 20/20 [01:07<00:00,  3.38s/it]\n",
      "  0%|                                   | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n",
      "Epoch [2/50], Step [0/20], D_loss: 0.0140, G_loss: 7.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▎                         | 1/20 [00:04<01:18,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch {i}\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██▋                        | 2/20 [00:07<01:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████                       | 3/20 [00:10<00:59,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████▍                     | 4/20 [00:14<00:54,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████▊                    | 5/20 [00:17<00:51,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████                   | 6/20 [00:20<00:47,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████▍                 | 7/20 [01:13<04:12, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████▊                | 8/20 [01:16<02:50, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████▏              | 9/20 [01:19<01:58, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████             | 10/20 [01:22<01:24,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n",
      "Epoch [2/50], Step [10/20], D_loss: 0.0000, G_loss: 75.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████▎           | 11/20 [01:26<01:02,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch {i}\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████▌          | 12/20 [01:29<00:45,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████▉         | 13/20 [01:32<00:34,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████▏       | 14/20 [01:35<00:25,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████▌      | 15/20 [01:38<00:19,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████▊     | 16/20 [01:41<00:14,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████    | 17/20 [01:44<00:10,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████▍  | 18/20 [01:47<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "if ifTrain == True:\n",
    "    \n",
    "    # Define loss function and optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch in enumerate(tqdm(data_loader)):\n",
    "            # Unpack the batch\n",
    "            simulated_map, measured_map = batch\n",
    "            print(simulated_map.size())\n",
    "    \n",
    "            # Move tensors to device\n",
    "            simulated_map = simulated_map.to(device)\n",
    "            measured_map = measured_map.to(device)\n",
    "    \n",
    "    \n",
    "            ############################\n",
    "            # Train discriminator\n",
    "            ############################\n",
    "            d_optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    \n",
    "            # Train with real data\n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "            # Concatenate the simulated map and measured map along the channel dimension\n",
    "            real_inputs = torch.cat((simulated_map, measured_map), dim=1)\n",
    "            real_outputs = discriminator(real_inputs)\n",
    "    #        print(f\"real label: {real_labels.size()}\")\n",
    "    #        print(f\"real output: {real_outputs.size()}\")\n",
    "            d_loss_real = criterion(real_outputs.squeeze(), real_labels.squeeze())\n",
    "            d_loss_real.backward()\n",
    "    \n",
    "            # Train with fake data\n",
    "            noise_map = torch.randn(batch_size, noise_dim, pixel_size, pixel_size, device=device)\n",
    "            fake_images = generator(simulated_map, noise_map)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "    #        print(f\"fake image size @generator's output: {fake_images.size()}\")\n",
    "    #        print(f\"simulated_map size: {simulated_map.size()}\")\n",
    "            fake_inputs = torch.cat((simulated_map, fake_images), dim=1)\n",
    "            fake_outputs = discriminator(fake_inputs)\n",
    "    #        print(f\"fake label: {fake_labels.size()}\")\n",
    "    #        print(f\"fake output: {fake_outputs.size()}\")\n",
    "            d_loss_fake = criterion(fake_outputs.squeeze(), fake_labels.squeeze())\n",
    "            d_loss_fake.backward()\n",
    "    \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_optimizer.step()\n",
    "    \n",
    "            ############################\n",
    "            # Train generator\n",
    "            ############################\n",
    "            g_optimizer.zero_grad()\n",
    "    \n",
    "            # Generate fake images\n",
    "            noise_map = torch.randn(batch_size, noise_dim, pixel_size, pixel_size, device=device)\n",
    "            fake_images = generator(simulated_map, noise_map)\n",
    "    \n",
    "            # Train generator with discriminator feedback\n",
    "            fake_inputs = torch.cat((simulated_map, fake_images), dim=1)\n",
    "            outputs = discriminator(fake_inputs)\n",
    "            g_loss = criterion(outputs.squeeze(), real_labels.squeeze())\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "            ############################\n",
    "            # Print losses\n",
    "            ############################\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(data_loader)}], \"\n",
    "                      f\"D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
    "                if ifSaveModel == True:\n",
    "                    torch.save(generator.state_dict(), 'generator_trained.pth')\n",
    "                    torch.save(generator, 'generator_entire_model.pth')\n",
    "                    print(\"Model saved at epoch {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece68b0-4275-4f02-ba82-e1325c5ecb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(noise_dim).to(device)\n",
    "generator.load_state_dict(torch.load('generator_trained.pth'))\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955c147-6141-4152-87e7-7dbd262aca94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be576201-0e0d-4879-939a-a9e149d13060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new image\n",
    "#from synthetic_map import generate_image\n",
    "def generate_image(generator, simulated_map, noise_dim):\n",
    "    # Prepare simulated map and noise map\n",
    "    simulated_map = simulated_map.to(device)\n",
    "    noise_map = torch.randn(1, noise_dim, pixel_size, pixel_size, device=device)\n",
    "\n",
    "    # Generate image\n",
    "    with torch.no_grad():\n",
    "        generated_image = generator(simulated_map, noise_map)\n",
    "    \n",
    "    return generated_image\n",
    "\n",
    "simulated_map = torch.from_numpy(image_dpm_np).reshape(1, 1 , pixel_size, pixel_size)\n",
    "synthetic_image = generate_image(generator, simulated_map, noise_dim).numpy()\n",
    "synthetic_image = synthetic_image.squeeze()\n",
    "print(synthetic_image.shape)\n",
    "#print(generated_image.size())\n",
    "\n",
    "# Plot the image\n",
    "\n",
    "plt.imshow(image_dpm_np, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(synthetic_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ec881-a0e7-4052-b3a4-b139a130ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_image.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1091d-7dc8-476d-8109-b89830a4ceba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
