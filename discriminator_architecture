digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140416245321776 [label="
 (1, 1, 1, 1)" fillcolor=darkolivegreen1]
	140417698901888 [label=SigmoidBackward0]
	140417698892240 -> 140417698901888
	140417698892240 [label=ConvolutionBackward0]
	140417698897232 -> 140417698892240
	140417698897232 [label=LeakyReluBackward1]
	140417698896992 -> 140417698897232
	140417698896992 [label=CudnnBatchNormBackward0]
	140417698897328 -> 140417698896992
	140417698897328 [label=ConvolutionBackward0]
	140417699059248 -> 140417698897328
	140417699059248 [label=LeakyReluBackward1]
	140417699053632 -> 140417699059248
	140417699053632 [label=CudnnBatchNormBackward0]
	140417699060304 -> 140417699053632
	140417699060304 [label=ConvolutionBackward0]
	140417699057376 -> 140417699060304
	140417699057376 [label=LeakyReluBackward1]
	140417699060496 -> 140417699057376
	140417699060496 [label=CudnnBatchNormBackward0]
	140417699059200 -> 140417699060496
	140417699059200 [label=ConvolutionBackward0]
	140417699055840 -> 140417699059200
	140417699055840 [label=LeakyReluBackward1]
	140417699057232 -> 140417699055840
	140417699057232 [label=ConvolutionBackward0]
	140417699064144 -> 140417699057232
	140415518278256 [label="main.0.weight
 (64, 2, 4, 4)" fillcolor=lightblue]
	140415518278256 -> 140417699064144
	140417699064144 [label=AccumulateGrad]
	140417699056992 -> 140417699059200
	140417204010768 [label="main.2.weight
 (128, 64, 4, 4)" fillcolor=lightblue]
	140417204010768 -> 140417699056992
	140417699056992 [label=AccumulateGrad]
	140417699056272 -> 140417699060496
	140417178445328 [label="main.3.weight
 (128)" fillcolor=lightblue]
	140417178445328 -> 140417699056272
	140417699056272 [label=AccumulateGrad]
	140417699060928 -> 140417699060496
	140417180180752 [label="main.3.bias
 (128)" fillcolor=lightblue]
	140417180180752 -> 140417699060928
	140417699060928 [label=AccumulateGrad]
	140417699056944 -> 140417699060304
	140417514939200 [label="main.5.weight
 (256, 128, 4, 4)" fillcolor=lightblue]
	140417514939200 -> 140417699056944
	140417699056944 [label=AccumulateGrad]
	140417699060352 -> 140417699053632
	140417514946320 [label="main.6.weight
 (256)" fillcolor=lightblue]
	140417514946320 -> 140417699060352
	140417699060352 [label=AccumulateGrad]
	140417699060544 -> 140417699053632
	140417514931840 [label="main.6.bias
 (256)" fillcolor=lightblue]
	140417514931840 -> 140417699060544
	140417699060544 [label=AccumulateGrad]
	140417699055456 -> 140417698897328
	140415517442512 [label="main.8.weight
 (512, 256, 4, 4)" fillcolor=lightblue]
	140415517442512 -> 140417699055456
	140417699055456 [label=AccumulateGrad]
	140417698897136 -> 140417698896992
	140417203744384 [label="main.9.weight
 (512)" fillcolor=lightblue]
	140417203744384 -> 140417698897136
	140417698897136 [label=AccumulateGrad]
	140417698902848 -> 140417698896992
	140417203738144 [label="main.9.bias
 (512)" fillcolor=lightblue]
	140417203738144 -> 140417698902848
	140417698902848 [label=AccumulateGrad]
	140417698892960 -> 140417698892240
	140417203733824 [label="main.11.weight
 (1, 512, 16, 16)" fillcolor=lightblue]
	140417203733824 -> 140417698892960
	140417698892960 [label=AccumulateGrad]
	140417698901888 -> 140416245321776
}
