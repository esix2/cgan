{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Data Parallelism with PyTorch for GAN Training\n",
    "\n",
    "This notebook demonstrates how to train a Generative Adversarial Network (GAN) using PyTorch's Distributed Data Parallelism (DDP) across multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, Dataset, DistributedSampler\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Generator model definition\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(noise_dim + 1, 64, 4, 2, 1, bias=False),  # Output: (64, 128, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),  # Output: (128, 64, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),  # Output: (256, 32, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),  # Output: (512, 16, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),  # Output: (1024, 8, 8)\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),  # Output: (512, 16, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # Output: (256, 32, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # Output: (128, 64, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),  # Output: (64, 128, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),  # Output: (1, 256, 256)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, simulated_map, noise_map):\n",
    "        input = torch.cat((simulated_map, noise_map), 1)\n",
    "        return self.main(input)\n",
    "\n",
    "# Discriminator model definition\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(2, 64, 4, 2, 1, bias=False),  # Input: (2, 256, 256) -> Output: (64, 128, 128)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),  # Output: (128, 64, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),  # Output: (256, 32, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),  # Output: (512, 16, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 2, 1, bias=False),  # Output: (1, 8, 8)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Custom dataset definition\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dpm_dir, irt_dir, transform=None):\n",
    "        self.dpm_dir = dpm_dir\n",
    "        self.irt_dir = irt_dir\n",
    "        self.transform = transform\n",
    "        self.dpm_images = sorted(os.listdir(dpm_dir))\n",
    "        self.irt_images = sorted(os.listdir(irt_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dpm_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dpm_image = Image.open(os.path.join(self.dpm_dir, self.dpm_images[idx]))\n",
    "        irt_image = Image.open(os.path.join(self.irt_dir, self.irt_images[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            dpm_image = self.transform(dpm_image)\n",
    "            irt_image = self.transform(irt_image)\n",
    "\n",
    "        return dpm_image, irt_image\n",
    "\n",
    "# Setup distributed environment\n",
    "def setup(rank, world_size):\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "# Build model and wrap with DDP\n",
    "def build_model(rank, noise_dim):\n",
    "    generator = Generator(noise_dim).to(rank)\n",
    "    discriminator = Discriminator().to(rank)\n",
    "    generator = DDP(generator, device_ids=[rank])\n",
    "    discriminator = DDP(discriminator, device_ids=[rank])\n",
    "    return generator, discriminator\n",
    "\n",
    "# Get DataLoader with DistributedSampler\n",
    "def get_data_loader(rank, world_size, batch_size):\n",
    "    dataset = CustomDataset(dpm_dir, irt_dir, transform=transform)\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    return data_loader\n",
    "\n",
    "# Train function\n",
    "def train(rank, world_size, noise_dim, batch_size, num_epochs, lr):\n",
    "    setup(rank,

